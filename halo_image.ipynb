{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import importlib.util\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib\n",
    "import os\n",
    "from crashpy.utilities import crashMemMap\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "# pretty print all cell's output and not just the last one\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### redshift_to_snap(redshift)\n",
    "Simple function which converts a redshift into the corresponing snapshot name to easily construct the path to the halo\n",
    "\n",
    "**Parameters**:\n",
    "- **redshift**: Redshift you want to convert (has to be 6,8 or 10)\n",
    "\n",
    "**Returns**:\n",
    "- **snapname**: Name of the snapshot the **redshift** corresponds to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redshift_to_snap(redshift):\n",
    "    snapnames = {6:'sn013', 8:'sn008', 10:'sn004'}\n",
    "    return snapnames[redshift]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_paths(halo_id, conf, redshift)\n",
    "Constructs the path to the output of the simulation as well as to the density map\n",
    "\n",
    "**Parameters**:\n",
    "- **halo_id**: ID of the halo to which you want to determine the path\n",
    "- **conf**: Configuration of the simulation e.g. 'fid2' \n",
    "- **redshift**: Redshift of the halo you want to examine\n",
    "\n",
    "**Returns**:\n",
    "- **simulation_path**: Path to the output maps of the simulation\n",
    "- **density_path**: Path to the density used in the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(halo_id, conf, redshift):\n",
    "    snap = redshift_to_snap(redshift)\n",
    "    conf_dir = os.path.join('/ptmp/mpa/mglatzle/TNG_f_esc', conf)\n",
    "    simulation_path =  os.path.join(conf_dir, f'run/L35n2160TNG/{snap}/g{halo_id}/Output/phys_ic00_rt05.out')\n",
    "    dens_path =  os.path.join(conf_dir, f'run/L35n2160TNG/{snap}/g{halo_id}/Input/dens_ic00.in')\n",
    "    return simulation_path, dens_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_H_map(halo)\n",
    "Simple function to calculate a map for xHI from xHII\n",
    "**Parameters**:\n",
    "- **halo**: Output of a simulation which should not be manipulated to ensure the map with index 1 is the HII map\n",
    "\n",
    "**Returns**:\n",
    "- **xHI**: Map containing the distribution of xHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_H_map(halo):\n",
    "    return np.ones(halo[1].shape)-halo[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_He_map(halo)\n",
    "Simple function to calculate a map for xHeI from xHeII and xHeII\n",
    "**Parameters**:\n",
    "- **halo**: Output of a simulation which should not be manipulated to ensure the map with index 2 and 3 are the HeII and HeII maps respectively\n",
    "\n",
    "**Returns**:\n",
    "- **xHeI**: Map containing the distribution of xHeI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_He_map(halo):\n",
    "    return np.ones(halo[1].shape)-halo[2]-halo[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_slice(cube, axis)\n",
    "Function which cuts out a slice from the center of the map along a given axis\n",
    "**Parameters**:\n",
    "- **cube**: Simulation map\n",
    "- **axis**: Axis along which you want to slice the halo\n",
    "\n",
    "**Returns**:\n",
    "- **map_slice**: Slice through the center of the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slice(cube, axis, method = 'slice', density = None):\n",
    "    center = cube.shape[0]//2\n",
    "    if method == 'slice':\n",
    "        if axis == 0:\n",
    "            map_slice = cube[center,...]\n",
    "        elif axis == 1:\n",
    "            map_slice = cube[:, center, :]\n",
    "        elif axis == 2:\n",
    "            map_slice = cube[:,:,center]\n",
    "        else:\n",
    "            raise ValueError('Axis number out of bounds')\n",
    "    else:\n",
    "        map_slice = get_projection(cube, axis=axis, method=method, density=density)\n",
    "    return map_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_projection(cube, axis, method, density):\n",
    "    if method == 'line_average':\n",
    "        map_slice = np.sum(cube, axis=axis)/cube.shape[0]\n",
    "    elif method == 'density_average':\n",
    "        dens_weighted = cube*density\n",
    "        map_slice = np.sum(dens_weighted, axis=axis)/np.sum(density, axis=axis)\n",
    "    elif method == 'test':\n",
    "        dens_weighted = cube*density\n",
    "        map_slice_dens = np.sum(dens_weighted, axis=axis)/np.sum(density, axis=axis)\n",
    "        map_slice_lin = np.sum(cube, axis=axis)/cube.shape[0]\n",
    "        map_slice = map_slice_lin-map_slice_dens\n",
    "    else:\n",
    "        error_message = f'Method {method} is not implemented'\n",
    "        raise NotImplementedError(error_message)\n",
    "    return map_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print_data(maps)\n",
    "Returns statistical information about the maps being examined\n",
    "\n",
    "**Parameters**:\n",
    "- **maps**: Dictionary of maps for which the statistical information is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data(maps):\n",
    "    for i, key in enumerate(maps):\n",
    "        if i == 0:\n",
    "            print(f'This halo has the shape {maps[key].shape}.')\n",
    "            print('*'*85)\n",
    "            \n",
    "        maxi = np.max(maps[key])\n",
    "        mini = np.min(maps[key])\n",
    "        average = np.average(maps[key])\n",
    "        median = np.median(maps[key])\n",
    "        print(f'''For {key} the max value is {maxi:.2f}, the min value is {mini:.2f}\n",
    "        , the average is {average:.2f} and the median is {median:.2f}.''')\n",
    "        print('*'*85)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_maps(halo_id, conf, redshift, props, get_data=False)\n",
    "Returns the density, temperature and ionization maps of a halo\n",
    "\n",
    "**Parameters**:\n",
    "- **halo_id**: ID of the halo to which you want to determine the path\n",
    "- **conf**: Configuration of the simulation e.g. 'fid2' \n",
    "- **redshift**: Redshift of the halo you want to examine\n",
    "- **props**: Properties for which you want to obtain the maps\n",
    "- **get_data**: Should a statistical summary of the maps be printed out (default: False)\n",
    "\n",
    "\n",
    "**Returns**:\n",
    "- **maps**: Dictionary containing **props** as keys and the corresponding maps as values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maps(halo_id, conf, redshift, props, get_data=False):\n",
    "    prop_dict = {'T':0, 'xHII':1, 'xHeII':2, 'xHeIII':3}\n",
    "    sim_path, dens_path = get_paths(halo_id, conf, redshift) \n",
    "    halo = crashMemMap(sim_path, 'all')\n",
    "    dens = crashMemMap(dens_path, 'all')\n",
    "    \n",
    "    maps = {}\n",
    "    for prop in props:\n",
    "        if prop in prop_dict:\n",
    "            maps[prop] = halo[prop_dict[prop]]\n",
    "        elif prop == 'xHI':\n",
    "            maps[prop] = get_H_map(halo)\n",
    "        elif prop == 'xHeI':\n",
    "            maps[prop] = get_He_map(halo)\n",
    "        elif prop == 'dens':\n",
    "            maps[prop] = dens[0]\n",
    "        else:\n",
    "            raise ValueError(f'The property {prop} does not exist.')\n",
    "    \n",
    "    if get_data:\n",
    "        print_data(maps)\n",
    "        \n",
    "    return maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot_maps(halo_id, conf, redshift, props, axis=0)\n",
    "Plots slices of the maps of props \n",
    "\n",
    "**Parameters**:\n",
    "- **halo_id**: ID of the halo to which you want to determine the path\n",
    "- **conf**: Configuration of the simulation e.g. 'fid2' \n",
    "- **redshift**: Redshift of the halo you want to examine\n",
    "- **props**: Properties for which you want to obtain the maps\n",
    "- **axis**: Axis along which you want to slice the halo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid_radius(r, r_v, side_length):\n",
    "    grid_r = r*side_length/(2*r_v)\n",
    "    return grid_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_compressor(old_dimension, new_dimension):\n",
    "    dim_compressor = np.zeros((new_dimension, old_dimension))\n",
    "    bin_size = float(old_dimension) / new_dimension\n",
    "    next_bin_break = bin_size\n",
    "    which_row = 0\n",
    "    which_column = 0\n",
    "    while which_row < dim_compressor.shape[0] and which_column < dim_compressor.shape[1]:\n",
    "        if round(next_bin_break - which_column, 10) >= 1:\n",
    "            dim_compressor[which_row, which_column] = 1\n",
    "            which_column += 1\n",
    "        elif next_bin_break == which_column:\n",
    "\n",
    "            which_row += 1\n",
    "            next_bin_break += bin_size\n",
    "        else:\n",
    "            partial_credit = next_bin_break - which_column\n",
    "            dim_compressor[which_row, which_column] = partial_credit\n",
    "            which_row += 1\n",
    "            dim_compressor[which_row, which_column] = 1 - partial_credit\n",
    "            which_column += 1\n",
    "            next_bin_break += bin_size\n",
    "    dim_compressor /= bin_size\n",
    "    return dim_compressor\n",
    "\n",
    "\n",
    "def get_column_compressor(old_dimension, new_dimension):\n",
    "    return get_row_compressor(old_dimension, new_dimension).transpose()\n",
    "\n",
    "def compress_and_average(array, new_shape):\n",
    "    # Note: new shape should be smaller in both dimensions than old shape\n",
    "    return np.mat(get_row_compressor(array.shape[0], new_shape[0])) * \\\n",
    "           np.mat(array) * \\\n",
    "           np.mat(get_column_compressor(array.shape[1], new_shape[1]))\n",
    "\n",
    "def source_pos(ID, redshift, conf, side_length):\n",
    "    snap = redshift_to_snap(redshift)\n",
    "    path_sources = f'/ptmp/mpa/mglatzle/TNG_f_esc/{conf}/run/L35n2160TNG/{snap}/g{ID}/Input/sources_ic00.in'\n",
    "    \n",
    "    # 0.5 is needed to take into account that the sources are at the center of the grid voxel, move origin to halo center\n",
    "    coord = pd.read_csv(path_sources, delim_whitespace=True, header=None, usecols=[0,1,2])\n",
    "    lum = pd.read_csv(path_sources, delim_whitespace=True, header=None, usecols=[3])\n",
    "    \n",
    "    coord = np.array(coord)\n",
    "    lum = np.vectorize(lum_str_to_float)(lum)\n",
    "\n",
    "    halo_cube = np.zeros((side_length,  side_length, side_length))\n",
    "    for i in range(coord.shape[0]):\n",
    "        pos = coord[i,:]\n",
    "        try:\n",
    "            halo_cube[pos[0],pos[1],pos[2]]+=lum[i][0]*1e52\n",
    "        except:\n",
    "            print(f'One stellar particle is at {pos}')\n",
    "    return halo_cube\n",
    "\n",
    "def project_pos(halo_cube, axis=0, size=None):\n",
    "    if size == None:\n",
    "        size = halo_cube.shape[0]\n",
    "    if size > halo_cube.shape[0]:\n",
    "        raise ValueError('Size of the projextion has to be smaller or equal to the size of the simulation cube')\n",
    "    projected = np.sum(halo_cube, axis=axis)\n",
    "    compressed_scaled = compress_and_average(projected, [size, size])\n",
    "    compressed = compressed_scaled*(projected.shape[0]/size)**2\n",
    "    return np.ma.filled(np.log10(np.ma.masked_equal(compressed, 0)), 0)\n",
    "\n",
    "def compressed_map(ID, redshift, conf, side_lenght, size=None, axis=0):\n",
    "    halo_cube = source_pos(ID, redshift, conf, side_lenght)\n",
    "    source_map = project_pos(halo_cube, axis, size=size)\n",
    "    return source_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_maps(halo_id, conf, redshift, init_props, r_v, r_m, axis=0, method='slice', \n",
    "              save=False, fesc=None, source_dens=False, source_width=None, appendix='', min_max=False, ranges=None):\n",
    "    titlesize = 40\n",
    "    \n",
    "    label_map = {'xHI':r'$x_\\mathrm{HI}$','xHII':r'$x_\\mathrm{HII}$',r'xHeI':'$x_\\mathrm{HeI}$',\n",
    "                 r'xHeII':'$x_\\mathrm{HeII}$','xHeIII':r'$x_\\mathrm{HeIII}$','T':r'$T[\\mathrm{K}]$',\n",
    "                 'dens':r'$n_{\\mathrm{gas}}[\\mathrm{cm}^{-3}]$'}\n",
    "    if min_max:\n",
    "        label_map['T'] = r'log$(T)[\\mathrm{K}]$'\n",
    "        label_map['dens'] = r'log$(n_{\\mathrm{gas}})[\\mathrm{cm}^{-3}]$'\n",
    "    all_props = ['T', 'dens', 'xHII', 'xHeII', 'xHeIII']\n",
    "    props = init_props.copy()\n",
    "    maps = get_maps(halo_id, conf, redshift, all_props)\n",
    "    with_source_dens = int(source_dens)\n",
    "    f, axarr = plt.subplots(len(props)+with_source_dens, 1)\n",
    "    \n",
    "    \n",
    "    if source_dens:\n",
    "        side_length = maps[list(maps.keys())[0]].shape[0]\n",
    "        source_map = compressed_map(halo_id, redshift, conf, side_length, size=source_width, axis=axis)\n",
    "        map_name = 'source_dens'\n",
    "        maps[map_name] = source_map\n",
    "        props.append(map_name)\n",
    "        label_map['source_dens'] = r'$\\log(Q_\\mathrm{sources})[s^{-1}]$'\n",
    "    \n",
    "    for i,key in enumerate(props):\n",
    "        side_length = maps[key].shape[0]\n",
    "        if (props[i] != 'T') and (props[i] != 'dens') and (props[i] != 'source_dens'):\n",
    "            norm = Normalize(0,1)\n",
    "        elif props[i] == 'source_dens':\n",
    "            norm = Normalize()\n",
    "        else:\n",
    "            norm = LogNorm()\n",
    "            \n",
    "        if (props[i] != 'source_dens'):\n",
    "            if props[i]=='dens':\n",
    "                method_to_use = 'line_average'\n",
    "            else:\n",
    "                method_to_use = method\n",
    "            plot_slice = get_slice(maps[key], axis, density=maps['dens'], method=method_to_use)\n",
    "            if (min_max and (props[i]=='T' or props[i]=='dens')):\n",
    "                subfig = axarr[i].imshow(np.log10(plot_slice), extent=[0,side_length,0,side_length], vmin=ranges[key]['vmin'], vmax=ranges[key]['vmax'] ,\n",
    "                                                 cmap=plt.get_cmap('inferno'))\n",
    "            else:\n",
    "                subfig = axarr[i].imshow(plot_slice, extent=[0,side_length,0,side_length], norm=norm, \n",
    "                                                 cmap=plt.get_cmap('inferno'))\n",
    "        else:\n",
    "            if (min_max and props[i]=='source_dens'):\n",
    "                subfig = axarr[i].imshow(maps[key], extent=[0,maps[key].shape[0],0,maps[key].shape[0]], vmin=ranges[key]['vmin'], vmax=ranges[key]['vmax'],\n",
    "                                                 cmap=plt.get_cmap('inferno'))\n",
    "            else:\n",
    "                subfig = axarr[i].imshow(maps[key], extent=[0,maps[key].shape[0],0,maps[key].shape[0]], norm=norm, \n",
    "                                                 cmap=plt.get_cmap('inferno'))\n",
    "        \n",
    "        \n",
    "        theta=np.linspace(0,2*np.pi,50)\n",
    "        r_virial = get_grid_radius(r_v,r_v, side_length)\n",
    "        r_mass = get_grid_radius(r_m,r_v, side_length)\n",
    "        \n",
    "        vir_x=np.cos(theta)*r_virial+side_length/2\n",
    "        vir_y=np.sin(theta)*r_virial+side_length/2\n",
    "        \n",
    "        mass_x=np.cos(theta)*r_mass+side_length/2\n",
    "        mass_y=np.sin(theta)*r_mass+side_length/2\n",
    "\n",
    "        axarr[i].plot(vir_x, vir_y, '--', linewidth=2, color='white')\n",
    "        axarr[i].plot(mass_x, mass_y, '--', linewidth=2, color='green')\n",
    "        axarr[i].set_yticklabels([])\n",
    "        axarr[i].set_xticklabels([])\n",
    "        axarr[i].set_ylabel(label_map[props[i]], size=40)\n",
    "        \n",
    "        divider = make_axes_locatable(axarr[i])\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "        cbar = f.colorbar(subfig, orientation='vertical',cax=cax)\n",
    "        cbar.ax.tick_params(labelsize=25)\n",
    "    if len(props)%3==1:\n",
    "        f.delaxes(axarr[int(np.floor(len(props)/3)), 1])\n",
    "        f.delaxes(axarr[int(np.floor(len(props)/3)), 2])\n",
    "    elif len(props)%3==2:\n",
    "        f.delaxes(axarr[int(np.floor(len(props)/3)), 2])\n",
    "    plt.rcParams[\"figure.figsize\"] = (5,4*len(props))\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(f'/u/ivkos/analysis/plots/{halo_id}_{method}_fesc{100*fesc:.1f}{appendix}.pdf', bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lum_str_to_float(string):\n",
    "    string = string.replace('d', 'e')\n",
    "    return float(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_dist_lum(ID, redshift, conf, side_length, r_v):\n",
    "    snap = redshift_to_snap(redshift)\n",
    "    path_sources = f'/ptmp/mpa/mglatzle/TNG_f_esc/{conf}/run/L35n2160TNG/{snap}/g{ID}/Input/sources_ic00.in'\n",
    "    \n",
    "    # 0.5 is needed to take into account that the sources are at the center of the grid voxel, move origin to halo center\n",
    "    coord = pd.read_csv(path_sources, delim_whitespace=True, header=None, usecols=[0,1,2])+0.5-side_length/2\n",
    "    lum = pd.read_csv(path_sources, delim_whitespace=True, header=None, usecols=[3])\n",
    "    dist = np.sqrt(np.sum(coord**2, axis=1))*2*r_v/side_length\n",
    "\n",
    "    dist_lum_df = pd.DataFrame({'dist':dist,'lum':lum[3]})\n",
    "    dist_lum_df.sort_values('dist', inplace=True)\n",
    "    \n",
    "    return dist_lum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mass_dens_r(dist_lum_df, frac, r_v):\n",
    "    lum = np.vectorize(lum_str_to_float)(dist_lum_df['lum'])\n",
    "    sorted_dist = np.array(dist_lum_df['dist'])\n",
    "\n",
    "    frac_lum = frac*lum.sum()\n",
    "    \n",
    "    radius_idx = 0\n",
    "    tot_lum = 0.\n",
    "    while tot_lum <= frac_lum:\n",
    "        prev_lum = tot_lum\n",
    "        tot_lum += lum[radius_idx]\n",
    "        radius_idx += 1\n",
    "        \n",
    "    contribution_idx1 = (tot_lum-frac_lum)/(tot_lum-prev_lum)\n",
    "    contribution_idx2 = 1-contribution_idx1\n",
    "    \n",
    "    r_frac = contribution_idx1*sorted_dist[radius_idx-2]+contribution_idx2*sorted_dist[radius_idx-1]\n",
    "    return r_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mass_rad(df, frac, conf):\n",
    "    radii = []\n",
    "    for index, row in df.iterrows():\n",
    "        dist_lum_df = source_dist_lum(ID=row.ID, redshift=row.z, conf=conf, side_length=row.GridSize, r_v=row.HaloRadii)\n",
    "        r_frac = mass_dens_r(dist_lum_df=dist_lum_df, frac=frac, r_v=row.HaloRadii)\n",
    "        radii.append(r_frac)\n",
    "    new_column_name = f'r_mass_{int(frac*100)}'\n",
    "    df[new_column_name] = radii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update_df(df)\n",
    "Simple function which updates the loaded dataframe with three additional columns for further analysis these clumns are **'Q0/HaloMass'** (total halo luminosity of halo mass), **'R_v^3/HaloMass'** (virial radius to the third power divided by the halo mass) and **'StarMass'** (just the mass of the stars in the halo)\n",
    "\n",
    "**Parameters**:\n",
    "- **df**: Dataframe that needs to be updated\n",
    "\n",
    "**Returns**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_df(df):\n",
    "    #df.set_index('ID', inplace=True)\n",
    "    df['Q0/HaloMass']=df['Q0']/df['HaloMass']\n",
    "    df['R_v^3/HaloMass']=df['HaloRadii']**3/df['HaloMass']\n",
    "    df['StarMass']= df['HaloMass']*df['FractionStars']*1e10/0.6774\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('dfs/esc_analysis_updated.pickle')\n",
    "update_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_mass_rad(df, 0.5, 'esc_analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_1 = 1544\n",
    "ID_2 = 2989 \t\n",
    "z_1 = 8\n",
    "z_2 = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.ID==ID_1)&(df.z==z_1)].HaloMass*1e10/0.6774\n",
    "df[(df.ID==ID_2)&(df.z==z_2)].HaloMass*1e10/0.6774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r_50_1 = float(df[(df.ID==ID_1)&(df.z==z_1)].r_mass_50)\n",
    "r_50_2 = float(df[(df.ID==ID_2)&(df.z==z_2)].r_mass_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_props = ['T', 'dens', 'xHII', 'xHeII', 'xHeIII']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_v_1 = float(df[(df.ID==ID_1)&(df.z==z_1)].HaloRadii)\n",
    "fesc_1 = float(df[(df.ID==ID_1)&(df.z==z_1)].f_esc)\n",
    "\n",
    "r_v_2 = float(df[(df.ID==ID_2)&(df.z==z_2)].HaloRadii)\n",
    "fesc_2 = float(df[(df.ID==ID_2)&(df.z==z_2)].f_esc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = {}\n",
    "ranges['dens'] = {}\n",
    "ranges['T'] = {}\n",
    "ranges['source_dens'] = {}\n",
    "\n",
    "ranges['dens']['vmin'] = -4\n",
    "ranges['dens']['vmax'] = 0\n",
    "\n",
    "ranges['T']['vmin'] = 3\n",
    "ranges['T']['vmax'] = 6\n",
    "\n",
    "ranges['source_dens']['vmin'] = 0\n",
    "ranges['source_dens']['vmax'] = 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_maps(ID_1, 'esc_analysis', z_1, init_props=init_props, r_v = r_v_1, r_m=r_50_1, axis=0, \n",
    "          method='density_average', save=True, fesc=fesc_1, source_dens=True, source_width=None, appendix='', min_max=True, ranges=ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_maps(ID_2, 'esc_analysis', z_2, init_props=init_props, r_v = r_v_2, r_m=r_50_2, axis=0, \n",
    "          method='density_average', save=True, fesc=fesc_2, source_dens=True, source_width=None, appendix='', min_max=True, ranges=ranges)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envcrash",
   "language": "python",
   "name": "envcrash"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
